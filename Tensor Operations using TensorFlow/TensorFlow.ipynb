{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPTbBybFi8jC0ZgDNpogdjo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshavardhangadila/Tensors-Operations/blob/main/Tensor%20Operations%20using%20TensorFlow/TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XZbLqiDEi4QE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds for reproducibility\n",
        "tf.random.set_seed(123)\n",
        "np.random.seed(123)"
      ],
      "metadata": {
        "id": "QGZahxx5jCPC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a scalar tensor\n",
        "scalar = tf.constant(10, dtype=tf.int32)\n",
        "\n",
        "# Creating a vector tensor\n",
        "vector = tf.constant([1.5, 2.5, 3.5], dtype=tf.float32)\n",
        "\n",
        "# Creating a matrix tensor\n",
        "matrix = tf.constant([[1, 2], [3, 4]], dtype=tf.int32)"
      ],
      "metadata": {
        "id": "Q2v0z7BjjCR5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking shape of tensor\n",
        "shape = matrix.shape\n",
        "\n",
        "# Checking datatype of tensor\n",
        "dtype = matrix.dtype\n",
        "\n",
        "# Checking number of dimensions\n",
        "ndim = matrix.ndim"
      ],
      "metadata": {
        "id": "WXHbL247jCU5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Casting tensor type\n",
        "vector_casted = tf.cast(vector, dtype=tf.float64)\n",
        "\n",
        "# Adding tensors\n",
        "added_tensor = vector + 2\n",
        "\n",
        "# Multiplying tensors\n",
        "multiplied_tensor = vector * 3"
      ],
      "metadata": {
        "id": "Hh22i-s5jCXq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing sum of elements\n",
        "sum_value = tf.reduce_sum(vector)"
      ],
      "metadata": {
        "id": "dCvZe3IyjCaZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication\n",
        "mat_A = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
        "mat_B = tf.constant([[5, 6], [7, 8]], dtype=tf.float32)\n",
        "mat_mul = tf.matmul(mat_A, mat_B)\n"
      ],
      "metadata": {
        "id": "iXzo8drGjCdX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transposing a matrix\n",
        "transposed_matrix = tf.transpose(mat_A)\n",
        "\n",
        "# Computing Frobenius norm\n",
        "norm_matrix = tf.norm(mat_A)\n",
        "\n",
        "# Concatenating tensors\n",
        "concat_tensor = tf.concat([vector, vector], axis=0)"
      ],
      "metadata": {
        "id": "-NzJ671MrxHu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacking tensors\n",
        "stacked_tensor = tf.stack([vector, vector], axis=1)\n",
        "\n",
        "# Expanding dimensions\n",
        "expanded_tensor = tf.expand_dims(vector, axis=0)\n",
        "\n",
        "# Squeezing dimensions\n",
        "squeezed_tensor = tf.squeeze(expanded_tensor)"
      ],
      "metadata": {
        "id": "boU8DnyMrxLp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Computing the maximum value in a tensor\n",
        "max_value = tf.reduce_max(vector)\n",
        "\n",
        "# Computing the mean of elements\n",
        "mean_value = tf.reduce_mean(vector)\n",
        "\n",
        "# Computing softmax\n",
        "softmax_values = tf.nn.softmax(vector)"
      ],
      "metadata": {
        "id": "RlqBRUX0r4Hw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing determinant of a matrix\n",
        "determinant = tf.linalg.det(mat_A)\n",
        "\n",
        "# Computing matrix inverse\n",
        "inverse_matrix = tf.linalg.inv(tf.constant([[4.0, 7.0], [2.0, 6.0]]))\n",
        "\n",
        "# Computing matrix trace\n",
        "trace_matrix = tf.linalg.trace(mat_A)"
      ],
      "metadata": {
        "id": "TIHoUmaRr4LQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing matrix rank\n",
        "rank_matrix = tf.rank(mat_A)\n",
        "\n",
        "# Computing element-wise division\n",
        "elementwise_div = mat_A / mat_B"
      ],
      "metadata": {
        "id": "P5S8OenjjChp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing eigenvalues and eigenvectors\n",
        "eigvals, eigvecs = tf.linalg.eigh(tf.constant([[6.0, 2.0], [2.0, 3.0]]))\n",
        "\n",
        "# Computing Cholesky decomposition\n",
        "cholesky_decomp = tf.linalg.cholesky(tf.constant([[4.0, 2.0], [2.0, 3.0]]))"
      ],
      "metadata": {
        "id": "2lB3luSjr-iy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing Singular Value Decomposition (SVD)\n",
        "s, u, v = tf.linalg.svd(mat_A)\n",
        "\n",
        "# Computing element-wise exponent\n",
        "exp_tensor = tf.exp(vector)"
      ],
      "metadata": {
        "id": "re7JF8tgr-nT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing element-wise logarithm\n",
        "log_tensor = tf.math.log(vector)\n",
        "\n",
        "# Computing cosine similarity\n",
        "cosine_sim = tf.tensordot(vector, vector, axes=1) / (tf.norm(vector) * tf.norm(vector))\n",
        "\n",
        "# Computing QR decomposition\n",
        "q, r = tf.linalg.qr(tf.cast(mat_A, tf.float32))"
      ],
      "metadata": {
        "id": "dOyzY8MQr-rq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing log determinant\n",
        "log_determinant = tf.linalg.logdet(tf.constant([[4.0, 7.0], [2.0, 6.0]]))\n",
        "\n",
        "# Computing batch matrix multiplication\n",
        "batch_A = tf.random.uniform((2, 3, 3))\n",
        "batch_B = tf.random.uniform((2, 3, 3))\n",
        "batch_matmul = tf.matmul(batch_A, batch_B)"
      ],
      "metadata": {
        "id": "L8dXumBCsHHF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing element-wise ReLU activation\n",
        "relu_tensor = tf.nn.relu(tf.constant([-1.0, 2.0, -3.0, 4.0]))\n",
        "\n",
        "# Computing standard deviation of a tensor\n",
        "std_dev = tf.math.reduce_std(tf.cast(vector, tf.float32))\n",
        "\n",
        "# Computing variance of a tensor\n",
        "variance = tf.math.reduce_variance(tf.cast(vector, tf.float32))"
      ],
      "metadata": {
        "id": "ePjyBbPTsHKd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor with normally distributed values\n",
        "normal_tensor = tf.random.normal((5, 5), mean=0, stddev=1)\n",
        "\n",
        "# Creating a tensor with a truncated normal distribution\n",
        "truncated_tensor = tf.random.truncated_normal((5, 5), mean=0, stddev=1)\n",
        "\n",
        "# Computing Hadamard (element-wise) product\n",
        "hadamard_product = mat_A * mat_B\n"
      ],
      "metadata": {
        "id": "tUMKcAHgsJZ2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication with higher dimensions\n",
        "mat_C = tf.random.uniform((4, 4), minval=0, maxval=10, dtype=tf.float32)\n",
        "mat_D = tf.random.uniform((4, 4), minval=0, maxval=10, dtype=tf.float32)\n",
        "mat_mul_high = tf.matmul(mat_C, mat_D)"
      ],
      "metadata": {
        "id": "xntoYZVDsJdf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transposing a higher-dimensional matrix\n",
        "transposed_high = tf.transpose(batch_A, perm=[0, 2, 1])\n",
        "\n",
        "# Computing inverse of a matrix\n",
        "matrix_inv_high = tf.linalg.inv(mat_C)\n",
        "\n",
        "# Computing matrix determinant\n",
        "matrix_det_high = tf.linalg.det(mat_C)\n",
        "\n",
        "# Computing Log Determinant\n",
        "log_det_high = tf.linalg.logdet(mat_C)"
      ],
      "metadata": {
        "id": "1QEM5LA8sOFv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing cosine similarity between two vectors\n",
        "vector_A = tf.random.uniform((5,), minval=0, maxval=10, dtype=tf.float32)\n",
        "vector_B = tf.random.uniform((5,), minval=0, maxval=10, dtype=tf.float32)\n",
        "cosine_sim_high = tf.tensordot(vector_A, vector_B, axes=1) / (tf.norm(vector_A) * tf.norm(vector_B))\n",
        "\n",
        "# Computing element-wise exponential\n",
        "exp_tensor_high = tf.exp(mat_C)\n"
      ],
      "metadata": {
        "id": "AeUg-0sGsOJZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing element-wise logarithm\n",
        "log_tensor_high = tf.math.log(mat_C + 1)  # Adding 1 to prevent log(0)\n",
        "\n",
        "# Applying ReLU activation\n",
        "relu_tensor_high = tf.nn.relu(tf.constant([-5.0, 2.0, -3.0, 7.0]))\n"
      ],
      "metadata": {
        "id": "xD2D4k-SsV7i"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display all results\n",
        "tensor_operations_results = {\n",
        "    \"Basic Operations\": {\n",
        "        \"Scalar Tensor\": scalar.numpy(),\n",
        "        \"Vector Tensor\": vector.numpy(),\n",
        "        \"Matrix Tensor\": matrix.numpy(),\n",
        "        \"Shape of Matrix\": shape,\n",
        "        \"Data Type\": dtype,\n",
        "        \"Number of Dimensions\": ndim,\n",
        "        \"Casted Vector Type\": vector_casted.dtype,\n",
        "        \"Added Tensor\": added_tensor.numpy(),\n",
        "        \"Multiplied Tensor\": multiplied_tensor.numpy(),\n",
        "        \"Sum of Elements\": sum_value.numpy(),\n",
        "    },\n",
        "    \"Medium Complexity Operations\": {\n",
        "        \"Matrix Multiplication\": mat_mul.numpy(),\n",
        "        \"Transposed Matrix\": transposed_matrix.numpy(),\n",
        "        \"Frobenius Norm\": norm_matrix.numpy(),\n",
        "        \"Concatenated Tensor\": concat_tensor.numpy(),\n",
        "        \"Stacked Tensor\": stacked_tensor.numpy(),\n",
        "        \"Expanded Tensor Shape\": expanded_tensor.shape,\n",
        "        \"Squeezed Tensor Shape\": squeezed_tensor.shape,\n",
        "        \"Maximum Value in Tensor\": max_value.numpy(),\n",
        "        \"Mean of Elements\": mean_value.numpy(),\n",
        "        \"Softmax of Vector\": softmax_values.numpy(),\n",
        "    },\n",
        "    \"Advanced Operations\": {\n",
        "        \"Eigenvalues\": eigvals.numpy(),\n",
        "        \"Eigenvectors\": eigvecs.numpy(),\n",
        "        \"Cholesky Decomposition\": cholesky_decomp.numpy(),\n",
        "        \"Singular Values\": s.numpy(),\n",
        "        \"Exponential Tensor\": exp_tensor.numpy(),\n",
        "        \"Logarithm Tensor\": log_tensor.numpy(),\n",
        "        \"Cosine Similarity\": cosine_sim.numpy(),\n",
        "        \"QR Decomposition Q\": q.numpy(),\n",
        "        \"QR Decomposition R\": r.numpy(),\n",
        "        \"Log Determinant\": log_determinant.numpy(),\n",
        "        \"Batch Matrix Multiplication\": batch_matmul.numpy(),\n",
        "        \"ReLU Activation\": relu_tensor.numpy(),\n",
        "    },\n",
        "    \"Complex Operations\": {\n",
        "        \"Matrix Multiplication High\": mat_mul_high.numpy(),\n",
        "        \"Matrix Inverse High\": matrix_inv_high.numpy(),\n",
        "        \"Matrix Determinant High\": matrix_det_high.numpy(),\n",
        "        \"Log Determinant High\": log_det_high.numpy(),\n",
        "        \"Cosine Similarity High\": cosine_sim_high.numpy(),\n",
        "        \"Exponential Tensor High\": exp_tensor_high.numpy(),\n",
        "        \"Logarithm Tensor High\": log_tensor_high.numpy(),\n",
        "        \"ReLU Activation High\": relu_tensor_high.numpy(),\n",
        "    }\n",
        "}\n",
        "\n",
        "print(tensor_operations_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIFm_Am9sV-1",
        "outputId": "18cba48e-00e9-4165-a756-97ab72132c2c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Basic Operations': {'Scalar Tensor': 10, 'Vector Tensor': array([1.5, 2.5, 3.5], dtype=float32), 'Matrix Tensor': array([[1, 2],\n",
            "       [3, 4]], dtype=int32), 'Shape of Matrix': TensorShape([2, 2]), 'Data Type': tf.int32, 'Number of Dimensions': 2, 'Casted Vector Type': tf.float64, 'Added Tensor': array([3.5, 4.5, 5.5], dtype=float32), 'Multiplied Tensor': array([ 4.5,  7.5, 10.5], dtype=float32), 'Sum of Elements': 7.5}, 'Medium Complexity Operations': {'Matrix Multiplication': array([[19., 22.],\n",
            "       [43., 50.]], dtype=float32), 'Transposed Matrix': array([[1., 3.],\n",
            "       [2., 4.]], dtype=float32), 'Frobenius Norm': 5.4772253, 'Concatenated Tensor': array([1.5, 2.5, 3.5, 1.5, 2.5, 3.5], dtype=float32), 'Stacked Tensor': array([[1.5, 1.5],\n",
            "       [2.5, 2.5],\n",
            "       [3.5, 3.5]], dtype=float32), 'Expanded Tensor Shape': TensorShape([1, 3]), 'Squeezed Tensor Shape': TensorShape([3]), 'Maximum Value in Tensor': 3.5, 'Mean of Elements': 2.5, 'Softmax of Vector': array([0.09003057, 0.24472848, 0.6652409 ], dtype=float32)}, 'Advanced Operations': {'Eigenvalues': array([1.9999999, 7.       ], dtype=float32), 'Eigenvectors': array([[-0.4472136,  0.8944272],\n",
            "       [ 0.8944272,  0.4472136]], dtype=float32), 'Cholesky Decomposition': array([[2.       , 0.       ],\n",
            "       [1.       , 1.4142135]], dtype=float32), 'Singular Values': array([5.4649854 , 0.36596614], dtype=float32), 'Exponential Tensor': array([ 4.481689, 12.182494, 33.11545 ], dtype=float32), 'Logarithm Tensor': array([0.40546513, 0.91629076, 1.252763  ], dtype=float32), 'Cosine Similarity': 1.0, 'QR Decomposition Q': array([[-0.3162278 , -0.9486833 ],\n",
            "       [-0.9486833 ,  0.31622773]], dtype=float32), 'QR Decomposition R': array([[-3.1622777 , -4.4271884 ],\n",
            "       [ 0.        , -0.63245535]], dtype=float32), 'Log Determinant': 2.9957323, 'Batch Matrix Multiplication': array([[[0.72927344, 0.5716828 , 0.14404717],\n",
            "        [1.5717154 , 1.0248424 , 0.48348585],\n",
            "        [1.0944614 , 0.7570255 , 0.27985233]],\n",
            "\n",
            "       [[0.52306616, 0.4563491 , 0.46249467],\n",
            "        [1.0093877 , 0.86679745, 0.86440766],\n",
            "        [0.9291225 , 0.8322909 , 0.7983096 ]]], dtype=float32), 'ReLU Activation': array([0., 2., 0., 4.], dtype=float32)}, 'Complex Operations': {'Matrix Multiplication High': array([[ 75.81592 , 105.19215 ,  68.89405 ,  86.360016],\n",
            "       [ 25.82193 , 100.23475 ,  45.258633,  60.11636 ],\n",
            "       [ 43.20284 ,  99.20391 ,  23.97472 ,  68.41944 ],\n",
            "       [ 42.99449 ,  85.89349 ,  69.86856 ,  60.862537]], dtype=float32), 'Matrix Inverse High': array([[ 0.07875811,  0.01328545,  0.07137002, -0.1012265 ],\n",
            "       [-0.31158024, -0.50408274,  0.28193605,  0.6539258 ],\n",
            "       [ 1.8993827 ,  2.5278964 , -2.0670362 , -2.7803895 ],\n",
            "       [-2.620956  , -3.2132468 ,  2.8082082 ,  3.7483547 ]],\n",
            "      dtype=float32), 'Matrix Determinant High': 83.28789, 'Log Determinant High': nan, 'Cosine Similarity High': 0.62366056, 'Exponential Tensor High': array([[1.5670474e+04, 1.1014471e+03, 8.8064117e+00, 1.9205081e+00],\n",
            "       [8.8299274e+00, 8.1347904e+00, 1.3559110e+03, 1.5491805e+02],\n",
            "       [1.5672086e+03, 1.9481252e+00, 3.2546066e+01, 1.4377235e+01],\n",
            "       [2.2412785e+01, 4.9027307e+02, 1.6314360e+02, 2.1094551e+01]],\n",
            "      dtype=float32), 'Logarithm Tensor High': array([[2.3664546 , 2.079989  , 1.1554588 , 0.50234365],\n",
            "       [1.1562983 , 1.1301594 , 2.1056244 , 1.7988834 ],\n",
            "       [2.1231058 , 0.5109461 , 1.5002159 , 1.2990046 ],\n",
            "       [1.4133334 , 1.9733812 , 1.8074082 , 1.3984736 ]], dtype=float32), 'ReLU Activation High': array([0., 2., 0., 7.], dtype=float32)}}\n"
          ]
        }
      ]
    }
  ]
}